# Week 2

Goal: Get comfortable with the basics of linear models (perceptrons)

**Learn**

- [x] `Watch` Learning from data, lecture 2 [Is learning feasible?](https://www.youtube.com/watch?v=MEG35RDD7RA&list=PLnIDYuXHkit4LcWjDe0EwlE57WiGlBs08&index=2)
- [x] `Watch` [But what is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk)
- [ ] `Review` https://github.com/dennybritz/nn-from-scratch
- [ ] `Review` https://github.com/cedrickchee/neural-network-in-13-lines
- [ ] `Review` https://iamtrask.github.io/2015/07/12/basic-python-network/

**Supplementary material**

- [ ] `Read` Chapter 2 from [Perceptrons: An introduction to computational geometry](https://mitpress.mit.edu/books/perceptrons)

**Do**

- [ ] Learning from data, homework 2
- [ ] Experiment with activation functions
- [ ] Two layer nework with backpropagation
- [ ] Implement the network in [Neural networks and deep learning, chapter 1](http://neuralnetworksanddeeplearning.com/chap1.html)

**Field reading**
- [x] Chapter 2 from [Complexity, a guided tour](https://www.amazon.se/Complexity-Guided-Tour-Melanie-Mitchell/dp/0199798109/)

**Distractions**
- [x] [Think like an educator about code quality](https://adamzerner.bearblog.dev/think-like-an-educator-about-code-quality/?utm_source=hnblogs.substack.com)